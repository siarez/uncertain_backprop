
Create a simple network to learn MNIST
Make the network similar to Ng's course assignment and replicate the results.
Plot learning rate and PDF on the delta's for each neuron in a mini-batch
Calculate stats for the delta's for each neuron
Update the back prop. to take into account uncertainty in delta's and measure performance (i.e. learning rate ... )
Measure to see if this method immunizes the network against random initilization of weights. Because to my experience with the perceptron sometimes the network can hit 0.91 accuracy after 4000 epochs sometime it flats out at 0.75 even after 50,000 epochs.

As the network learns, distribution of deltas  becomes narrower and centers around zero, because the network is making less mistakes.
If the adjustment favors output neurons with higher uncertainty in their delta's then neurons in the hidden layer can be seen as helping output neurons that are bad in predicting more than the ones that are good. But isn't that already built-in?

Types of distribution to look at:
    1. Dist. of deltas for a specific weight in batch
    2. Dist. of deltas coming in a neuron from neurons in the next layer.
    3. Dist. of input compared to dist of output
    4. what about distribution of weights? to or from a neuron?
    These distributions can be marginalized for classes in training data

Questions to ask from these distributions:
    1. What kind of information can you get from these distributions that you can't get from loss function?
    2. How can this information be leveraged?
    3. Can we determine over-fit and under fit?

    For the second type of dist., we can compare distribution of deltas coming from neurons in the next layer for a batch. One idea is that if there is a strong pull on delta from two different directions (two sharp peaks one smaller than zero and one bigger than zero) we can split the neuron to two.

    For the third type of dist, a neuron can remove itself, if there is a direct relationship between a neuron in the previous layer and a neuron in the next layer. Basically a neuron can find out if it is an unnecessary middle man.

    For the second type of dist., if the distribution is centered around zero but is wide, it means the network behind it it under fitting. It is interesting because it could tell us where to add neurons.

    For the 4th type of dist, maybe we can get rid of neurons that have a very uniform distribution of input wights. I think a very uniform weight distribution means the neuron isn't doing much?

    It also be interesting to see if looking at this distributions we could tell whether the network has too many dof and is prone to over fitting. It could help us in pruning the network.





